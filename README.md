# ODE-solver
  There are a number of ways to exactly solve a first order differential equation. To numerically solve a first order DE of the form u'=f(u,t), we require some numerical methods. Let's start with the Euler method. We are given an initial condition, $u(t_0)$. We want to know what u(t) is, at some unspecified time t. Let $t_0=a$ and $t_n=b$, where $t_n=t$. We can partition the interval [a,b] into n+1 equally spaced nodes, $t_0, t_1,....,t_n$. This is simple, given a step size h, $h=frac{\(b-a)}{\n}$, then $t_i = t_0 + i(h)$ for i=1,2,...n. Given a forward difference approximation of u' at $t_i$, $u'(t_i)= \frac{u(t_{i+1}) - u(t_i)}{h}$ for i=0,1,...n-1. This equation can be rearranged to be $u(t_{i+1})= u(t_i) + (h)u'(t_i)$ for i=0,1,...,n-1. This is Euler's method. Notice that for i=0, we already have the value of $u(t_i)$, and the differential equation is also given. Thus we can compute $u(t_1)$, and from that we can compute $u(t_2)$, and so on, until we get to $u(t_n)$. To discuss accuracy, we must understand the nature of the problem. $u(t_0)$ is an exact value, since it is our initial condition. But $u(t_1)$ is an approximation, since we are approximating the derivative $u'(t_0)$ with a forward difference formula. in fact, for all i>/= 1, we are approximating $t_i$, with the errors compounding additively. The truncation error, denoted $Tau_{i+1}(h)$, is the error between the exact derivative, $f(u(t_i), t_i)$, and the FD approximation. The pointwise error is the difference between the exact value, $\hat{u_{i+1}}$, and the approximation to it, assuming that $u_i$ is also exact. In the image, we prove that the pointwise error is O(h^2) and the truncation error is O(h). 
  Runge-Kutta is a more accurate method, as we will see. It involves taking multiple evaluations across the time step of length h. The improved Euler method is a simple example of this. Instead of using $f(u_i,t_i)$ as the derivative, we use $f(u_i+(h/2)f(u_i,t_i), t_i + h/2)$. The derivation of IE2 is the same, approximate the derivative using the same forward difference, and then solve for $u_{i+1}$. The pointwise error is O(h^3) and the truncation error becomes O(h^2), as shown in the image. RK4 is another method, taking 4 evaluations across the time step. The first evaluation is $k1= hf(u_i,t_i)$, the second is $k_2=hf(u_i +(1/2)k_1, t_i +(1/2)h)$, the third is $k_3=hf(u_i +(1/2)k_2, t_i +(1/2)h)$, the fourth is $k_4= hf(u_i+k_3, t_i + h)$. Then $u_{i+1}= u_{i} + (1/6)k_1 + (1/3)k_2 +(1/3)k_3 + (1/6)k_4$.
  K-multistep methods improve accruacy by using the history of the solution. Specifically, they use the last k values of u and f. Depending on whether the method is explicit or implicit, the i+1th value of f is included. Similar to all previous methods, we use Taylor expansions to determine that the order of accuracy of the truncation error is O(h) and the pointwise error is O(h^2). Adams-Bashforth 2 is a explcit 2-step method, using $u_i,u_{i-1}$ and $f_{i}, f_{i-1}$. Adams-Moulton 2 is an implicit 2-step method, using $u_i$ and $f_{i+1}, f_{i}$. 



![Solver Page 1](images/Euler%20.png)
![Solver Page 2](images/Runge%20Kutta%20and%20IE2.png)
![Solver Page 3](images/Adams%20Bashforth%20and%20Adams%20Moulton.png)
# diffrentiation

![formulas page 1](images/FD.png)
# integration 

![integration page 1](images/Romberg.png)
